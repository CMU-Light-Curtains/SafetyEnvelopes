from dataclasses import dataclass
from typing import Tuple, Optional, List
import numpy as np

import torch
import torch.nn as nn

from data.synthia import Frame
from devices.light_curtain import LCReturn
from policies.actors import Pi
from policies.actors.actor import Actor
import utils

ingr = utils.Ingredient("cnn1d")
ingr.add_config("config/networks/cnn1d.yaml")


@utils.register_class("network")
class CNN1D(Actor):
    @ingr.capture
    def __init__(self,
                 thetas: np.ndarray,
                 base_policy: Actor,
                 min_range: float,
                 max_range: float,
                 history: int,
                 smoothing: bool):
        """
        Args:
            thetas (np.ndarray, dtype=np.float32, shape=(C,)): thetas of the camera rays,
                in degrees and in increasing order in [-fov/2, fov/2]
            base_policy (Actor): a base policy that the residual policy policy uses.
            min_range (float): minimum range of the light curtain device
            max_range (float): maximum range of the light curtain device
            history (int): the number of previous observations the actor will use.
            smoothing (bool): whether to apply differentiable smoothing or not.
        """
        self.base_policy = base_policy

        self.thetas = thetas
        self.C = len(self.thetas)

        self.H = history
        self.history = utils.History(size=self.H)

        self.network = CNN(self.H, self.C, base_policy, smoothing)
        if torch.cuda.is_available():
            self.network = self.network.cuda()

    @dataclass
    class Datum:
        i: np.ndarray  # 1D vector of LC intensities
        x: np.ndarray  # 1D vector of LC placement's x
        z: np.ndarray  # 1D vector of LC placement's z
        r: np.ndarray  # 1D vector of LC placement's r
        b: np.ndarray  # 1D vector of base policy's placement

    @property
    def feat_dim(self) -> List[int]:
        return [5 * self.H, self.C]  # 5H features: i, x, z, r, b vectors per timestep

    def init_action(self,
                    init_envelope: np.ndarray) -> Tuple[np.ndarray, Optional[np.ndarray], dict]:
        """
        Args:
            init_envelope (np.ndarray, dtype=np.float32, shape=(C,)): the initial envelope provided by the environment.

        Returns:
            action (np.ndarray, dtype=np.float32, shape=(C,)): action, in terms of ranges for each camera ray.
            logp_a (Optional[np.ndarray]): log-probability of the sampled actions. None if sampling is deterministic.
            info (dict): auxiliary info generated by policy, such as a vector representation of the observation while
                         generating the action.
        """
        act, logp_a, info = self.base_policy.init_action(init_envelope)  # use base policy
        return act, None, {}

    @torch.no_grad()
    def step(self,
             obs: LCReturn) -> Tuple[np.ndarray, Optional[np.ndarray], bool, dict]:
        """
        Args:
            obs (LCReturn): observations viz return from the front light curtain.

        Returns:
            act (np.ndarray, dtype=np.float32, shape=(C,)): sampled actions -- these are absolute, not residual.
            logp_a (Optional[np.ndarray]): log-probability of the sampled actions. None if sampling is deterministic.
            control (bool): whether this policy had control of taking the action at this timestep.
                            - this will be used to determine whether to evaluate the policy at this frame.
                            - another eg. is that these are the timesteps when nn-based policies will run the network.
            info (dict): auxiliary info generated by policy, such as a vector representation of the observation while
                         generating the action.
        """
        self.network.eval()

        # get placement and intensities from observation
        i = obs.bev_intensities() / 255.0  # (C,)
        r = obs.lc_ranges  # (C,)
        design_pts = utils.design_pts_from_ranges(r, self.thetas)  # (C, 2)
        x = design_pts[:, 0]  # (C,)
        z = design_pts[:, 1]  # (C,)

        # get placement of base policy
        b, _, _, _ = self.base_policy.step(obs)  # (C,)

        # create datum of current timestep and add to history
        datum = CNN1D.Datum(i, x, z, r, b)
        self.history.add(datum)

        # create features from history
        inputs = sum([[d.i, d.x, d.z, d.r, d.b] for d in self.history.get()], [])  # list of 5H vectors of shape (C,)
        feat = np.stack(inputs, axis=0)  # (5H, C)

        # action from network
        feat_tensor = torch.from_numpy(feat).unsqueeze(dim=0)  # (1, 5H, C)
        if torch.cuda.is_available():
            feat_tensor = feat_tensor.cuda()
        pi: Pi = self.forward(feat_tensor)  # batch_shape=(1, C) event_shape=()
        act, _ = pi.sample()  # both (1, C)
        act = act.squeeze(0).cpu().numpy()  # (C,) dtype=float32

        logp_a  = None
        control = True
        info    = dict(
            features=feat,  # (5H, C)
            pi=pi  # batch_shape=(1, C) event_shape=()
        )
        return act, logp_a, control, info

    def forward(self,
                feats: torch.Tensor) -> Pi:
        """
        Args:
            feats (torch.Tensor, dtype=float32, shape=(B, 5H, C, R)): features.

        Returns:
             pi (Pi, batch_shape=(B, C), event_shape=()): action distribution.
        """
        pi: Pi = self.network(feats)  # batch_shape=(B, C) event_shape=()
        return pi

    def reset(self):
        super().reset()
        self.history.clear()

########################################################################################################################
# region Convolutional Neural Networks
########################################################################################################################


class ResidualBlock(nn.Module):
    """Based on Figure 2 in this paper: https://arxiv.org/pdf/1512.03385.pdf"""
    def __init__(self, F):
        super().__init__()

        self.conv1 = nn.Conv1d(F, F, kernel_size=5, padding=2)
        self.conv2 = nn.Conv1d(F, F, kernel_size=5, padding=2)

    def forward(self,
                x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x (torch.Tensor, dtype=float32, shape=(B, F, C)): input
        """
        identity = x

        x = self.conv1(x)  # (B, F, C)
        x = torch.relu(x)  # (B, F, C)
        x = self.conv2(x)  # (B, F, C)
        x = x + identity   # (B, F, C)
        x = torch.relu(x)  # (B, F, C)

        return x


class CNN(nn.Module):
    """Performs 1D convolutions"""
    def __init__(self,
                 H: int,
                 C: int,
                 base_policy: Actor,
                 smoothing: bool):
        super().__init__()
        self.smoothing = smoothing

        # filter sizes are hardcoded for history=5
        assert H == 5

        self.conv1 = nn.Conv1d(25, 12, kernel_size=5, padding=2)
        self.conv2 = nn.Conv1d(12,  6, kernel_size=5, padding=2)
        self.conv3 = nn.Conv1d( 6,  1, kernel_size=5, padding=2)

        # F = 5 * H
        #
        # self.layer1 = ResidualBlock(F)
        # self.layer2 = ResidualBlock(F)
        # self.last_conv = nn.Conv1d(F, 1, kernel_size=5, padding=2)

        self.smoothness_matrix = self._create_smoothness_matrix(C, base_policy._SMOOTHNESS)

        num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"{self.__class__.__name__}: has {num_params} parameters")

    @staticmethod
    def _create_smoothness_matrix(C, smoothness):
        # pre-compute smoothness_deltas:
        # the maximum differences in ranges values between pairs of camera rays
        arange = np.arange(C, dtype=np.float32)  # (C,)
        smoothness_matrix = np.abs(arange.reshape(1, -1) - arange.reshape(-1, 1)) * smoothness  # (C, C)

        # smoothness matrix
        smoothness_matrix = torch.from_numpy(smoothness_matrix)  # (C, C)
        if torch.cuda.is_available():
            smoothness_matrix = smoothness_matrix.cuda()  # (C, C)
        smoothness_matrix.unsqueeze_(dim=0)  # (1, C, C)

        return smoothness_matrix

    def forward(self,
                feat: torch.Tensor) -> Pi:
        """
        Args:
            feat (torch.Tensor, dtype=np.float32, shape=(B, 5H, C)): batch-wise input features.

        Returns:
            pi (Pi, batch_shape=(B, C), event_shape=()): action distribution
        """
        x = feat  # (B, 25, C)

        x = torch.relu(self.conv1(x))    # (B, 12, C)
        x = torch.relu(self.conv2(x))    # (B,  6, C)
        x = torch.square(self.conv3(x))  # (B,  1, C)

        # x = self.layer1(x)  # (B, 5H, C)
        # x = self.layer2(x)  # (B, 5H, C)
        # x = torch.square(self.last_conv(x))  # (B,  1, C)

        if self.smoothing:
            x = x + self.smoothness_matrix  # (B, C, C)
            x = x.min(dim=2, keepdim=True)[0]  # (B, C, 1)
        else:
            x = x.transpose(1, 2)  # (B, C, 1)

        pi = Pi(actions=x)  # BS=(B, C), ES=()
        return pi

# endregion
########################################################################################################################
